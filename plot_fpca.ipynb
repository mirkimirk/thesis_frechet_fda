{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Functional Principal Component Analysis\n",
    "\n",
    "Explores the two possible ways to do functional principal component analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Yujian Hong\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import skfda\n",
    "from skfda.datasets import fetch_growth\n",
    "from skfda.exploratory.visualization import FPCAPlot\n",
    "from skfda.preprocessing.dim_reduction import FPCA\n",
    "from skfda.representation.basis import (\n",
    "    BSplineBasis,\n",
    "    FourierBasis,\n",
    "    MonomialBasis,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are going to use functional principal component analysis\n",
    "to explore datasets and obtain conclusions about said dataset using this\n",
    "technique.\n",
    "\n",
    "First we are going to fetch the Berkeley Growth Study data. This dataset\n",
    "correspond to the height of several boys and girls measured from birth to\n",
    "when they are 18 years old. The number and time of the measurements are the\n",
    "same for each individual. To better understand the data we plot it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = skfda.datasets.fetch_growth()\n",
    "fd = dataset[\"data\"]\n",
    "y = dataset[\"target\"]\n",
    "fd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FPCA can be done in two ways. The first way is to operate directly with the\n",
    "raw data. We call it discretized FPCA as the functional data in this case\n",
    "consists in finite values dispersed over points in a domain range.\n",
    "We initialize and setup the FPCADiscretized object and run the fit method to\n",
    "obtain the first two components. By default, if we do not specify the number\n",
    "of components, it's 3. Other parameters are weights and centering. For more\n",
    "information please visit the documentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpca_discretized = FPCA(n_components=2)\n",
    "fpca_discretized.fit(fd)\n",
    "fpca_discretized.components_.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second case, the data is first converted to use a basis representation\n",
    "and the FPCA is done with the basis representation of the original data.\n",
    "We obtain the same dataset again and transform the data to a basis\n",
    "representation. This is because the FPCA module modifies the original data.\n",
    "We also plot the data for better visual representation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd.data_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_growth()\n",
    "fd = dataset[\"data\"]\n",
    "basis = skfda.representation.basis.BSplineBasis(n_basis=7)\n",
    "basis_fd = fd.to_basis(basis)\n",
    "basis_fd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We initialize the FPCABasis object and run the fit function to obtain the\n",
    "first 2 principal components. By default the principal components are\n",
    "expressed in the same basis as the data. We can see that the obtained result\n",
    "is similar to the discretized case.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basis_fd.basis(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpca = FPCA(n_components=2)\n",
    "fpca.fit(basis_fd)\n",
    "fpca.components_.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better illustrate the effects of the obtained two principal components,\n",
    "we add and subtract a multiple of the components to the mean function.\n",
    "We can then observe now that this principal component represents the\n",
    "variation in the mean growth between the children.\n",
    "The second component is more interesting. The most appropriate explanation is\n",
    "that it represents the differences between girls and boys. Girls tend to grow\n",
    "faster at an early age and boys tend to start puberty later, therefore, their\n",
    "growth is more significant later. Girls also stop growing early\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FPCAPlot(\n",
    "    basis_fd.mean(),\n",
    "    fpca.components_,\n",
    "    factor=30,\n",
    "    fig=plt.figure(figsize=(6, 2 * 4)),\n",
    "    n_rows=2,\n",
    ").plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also specify another basis for the principal components as argument\n",
    "when creating the FPCABasis object. For example, if we use the Fourier basis\n",
    "for the obtained principal components we can see that the components are\n",
    "periodic. This example is only to illustrate the effect. In this dataset, as\n",
    "the functions are not periodic it does not make sense to use the Fourier\n",
    "basis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_growth()\n",
    "fd = dataset[\"data\"]\n",
    "basis_fd = fd.to_basis(BSplineBasis(n_basis=7))\n",
    "fpca = FPCA(n_components=2, components_basis=FourierBasis(n_basis=7))\n",
    "fpca.fit(basis_fd)\n",
    "fpca.components_.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe that if we switch to the Monomial basis, we also lose the\n",
    "key features of the first principal components because it distorts the\n",
    "principal components, adding extra maximums and minimums. Therefore, in this\n",
    "case the best option is to use the BSpline basis as the basis for the\n",
    "principal components\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_growth()\n",
    "fd = dataset[\"data\"]\n",
    "basis_fd = fd.to_basis(BSplineBasis(n_basis=7))\n",
    "fpca = FPCA(n_components=2, components_basis=MonomialBasis(n_basis=4))\n",
    "fpca.fit(basis_fd)\n",
    "fpca.components_.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenes Zeug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def riemann_sum(a, b, m, f, method=\"left\"):\n",
    "    \"\"\"Compute integral.\"\"\"\n",
    "    stepsize = (b - a) / m\n",
    "    if method == \"left\":\n",
    "        grid = np.linspace(a, b - stepsize, m)\n",
    "    elif method == \"right\":\n",
    "        grid = np.linspace(a + stepsize, b, m)\n",
    "    else:\n",
    "        msg = \"Must specify either left or right Riemann sum!\"\n",
    "        raise ValueError(msg)\n",
    "    return sum(f(grid) * stepsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate synthetic functional data\n",
    "n_curves = 100\n",
    "n_points = 100\n",
    "x = np.linspace(0, 1, n_points)\n",
    "# Generate curves with some random variation around a sine curve\n",
    "data = np.array(\n",
    "    [\n",
    "        np.sin(4 * np.pi * x)\n",
    "        + 0.5 * np.random.default_rng(seed=_).normal(0, 0.5, len(x))\n",
    "        for _ in range(n_curves)\n",
    "    ],\n",
    ")\n",
    "\n",
    "# 2. Compute the mean function\n",
    "mean_function = np.mean(data, axis=0)\n",
    "\n",
    "# 3. Center the data\n",
    "centered_data = data - mean_function\n",
    "\n",
    "# 4. Estimate the covariance function using a discrete approximation\n",
    "cov_matrix = np.cov(centered_data, rowvar=False)\n",
    "\n",
    "# 5. Compute the eigenfunctions (principal components) of the covariance matrix\n",
    "eigenvalues, eigenfunctions = np.linalg.eigh(cov_matrix)\n",
    "\n",
    "# Sort eigenvalues and eigenfunctions in decreasing order\n",
    "eigenvalues = eigenvalues[::-1]\n",
    "eigenfunctions = eigenfunctions[:, ::-1]\n",
    "\n",
    "# Compute the L^2 norm for each column (eigenvector) over the domain\n",
    "l2_norms = np.sqrt(np.trapz(eigenfunctions**2, x, axis=0))\n",
    "\n",
    "# Scale each column of the eigenfunctions matrix by its respective L^2 norm using broadcasting\n",
    "eigenfunctions_scaled = eigenfunctions / l2_norms\n",
    "\n",
    "# Adjust the lambda function to handle array input and interpolate values from the eigenvector\n",
    "# Compute the L^2 norm for each column (eigenvector) over the domain using riemann_sum\n",
    "l2_norms_riemann = np.array(\n",
    "    [\n",
    "        np.sqrt(\n",
    "            riemann_sum(\n",
    "                0,\n",
    "                1,\n",
    "                n_points,\n",
    "                lambda grid: np.interp(grid, x, eigenfunctions[:, i] ** 2),\n",
    "            ),\n",
    "        )\n",
    "        for i in range(n_points)\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Scale each column of the eigenfunctions matrix by its respective L^2 norm using broadcasting\n",
    "eigenfunctions_scaled_riemann = eigenfunctions / l2_norms_riemann\n",
    "\n",
    "# Check the first few L^2 norms to verify\n",
    "first_few_norms_riemann = np.array(\n",
    "    [\n",
    "        riemann_sum(\n",
    "            0,\n",
    "            1,\n",
    "            n_points,\n",
    "            lambda grid: np.interp(grid, x, eigenfunctions_scaled_riemann[:, i] ** 2),\n",
    "        )\n",
    "        for i in range(5)\n",
    "    ],\n",
    ")\n",
    "first_few_norms_riemann\n",
    "\n",
    "\n",
    "# 6. Project the centered data onto the eigenfunctions\n",
    "fpca_scores = np.dot(centered_data, eigenfunctions)\n",
    "\n",
    "# Plot the mean function and the first two eigenfunctions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(x, mean_function, \"b-\")\n",
    "plt.title(\"Mean Function\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(x, eigenfunctions[:, 0], \"r-\")\n",
    "plt.title(\"1st Eigenfunction\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(x, eigenfunctions[:, 1], \"g-\")\n",
    "plt.title(\"2nd Eigenfunction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
