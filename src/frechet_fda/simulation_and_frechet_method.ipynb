{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This module implements the Fréchet regression method from Petersen and Müller 2019.\\n\\nThe method is implemented in the context of estimation in the space of distribution\\nfunctions. Also, a simulation study is designed to compare with the methods outlined in\\nPetersen and Müller 2016.\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This module implements the Fréchet regression method from Petersen and Müller 2019.\n",
    "\n",
    "The method is implemented in the context of estimation in the space of distribution\n",
    "functions. Also, a simulation study is designed to compare with the methods outlined in\n",
    "Petersen and Müller 2016.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'frechet_fda'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Coding\\thesis_frechet_fda\\src\\frechet_fda\\simulation_and_frechet_method.ipynb Cell 2\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Coding/thesis_frechet_fda/src/frechet_fda/simulation_and_frechet_method.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Coding/thesis_frechet_fda/src/frechet_fda/simulation_and_frechet_method.ipynb#W1sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtqdm\u001b[39;00m \u001b[39mimport\u001b[39;00m tqdm\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Coding/thesis_frechet_fda/src/frechet_fda/simulation_and_frechet_method.ipynb#W1sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfrechet_fda\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconfig\u001b[39;00m \u001b[39mimport\u001b[39;00m BLD\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Coding/thesis_frechet_fda/src/frechet_fda/simulation_and_frechet_method.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfrechet_fda\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata_generation_tools\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Coding/thesis_frechet_fda/src/frechet_fda/simulation_and_frechet_method.ipynb#W1sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     gen_params_regression,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Coding/thesis_frechet_fda/src/frechet_fda/simulation_and_frechet_method.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m     gen_predictor_values_regression,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Coding/thesis_frechet_fda/src/frechet_fda/simulation_and_frechet_method.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     make_estimated_pdf,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Coding/thesis_frechet_fda/src/frechet_fda/simulation_and_frechet_method.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Coding/thesis_frechet_fda/src/frechet_fda/simulation_and_frechet_method.ipynb#W1sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfrechet_fda\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtools\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfrechet_tools\u001b[39;00m \u001b[39mimport\u001b[39;00m ise_wasserstein, solve_frechet_qp\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'frechet_fda'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from frechet_fda.config import SRC\n",
    "from frechet_fda.tools.data_generation_tools import (\n",
    "    gen_params_regression,\n",
    "    gen_predictor_values_regression,\n",
    "    gen_sample_points_from_qfs,\n",
    "    gen_y_qf,\n",
    "    make_estimated_pdf,\n",
    ")\n",
    "from frechet_fda.tools.frechet_tools import ise_wasserstein, solve_frechet_qp\n",
    "from frechet_fda.tools.function_tools import (\n",
    "    get_optimal_range,\n",
    "    inverse_log_qd_transform,\n",
    "    log_qd_transform,\n",
    "    mean_func,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "seed = 28071995\n",
    "predictor_bounds = (-1, 1)\n",
    "mu_params_dict = {\"mu0\": 0, \"beta\": 3, \"v1\": 0.25}\n",
    "sigma_params_dict = {\"sigma0\": 3, \"gamma\": 0.5, \"v2\": 2}\n",
    "\n",
    "# Define u grid on which to evaluate function points\n",
    "grid_size = 500\n",
    "grid_to_predict_size = 50\n",
    "delta = 0  # can start bounded away from zero and one\n",
    "u = np.linspace(delta, 1 - delta, grid_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_vals = gen_predictor_values_regression(N, predictor_bounds, seed)\n",
    "mus, sigmas = gen_params_regression(\n",
    "    mu_params_dict, sigma_params_dict, predictor_vals, seed,\n",
    ")\n",
    "predictor_vals.shape, mus.shape, sigmas.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only every \"slicing_size\"th value of predictor grid to calculate estimate\n",
    "x_grid = np.linspace(-1, 1, grid_to_predict_size)\n",
    "x_grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qfs = gen_y_qf(mus, sigmas, u)\n",
    "qfs = [qf.drop_inf() for qf in qfs]\n",
    "qfs[0].y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select which qfs to compare\n",
    "first_qf_to_compare = 0\n",
    "second_qf_to_compare = 199\n",
    "\n",
    "qfs[first_qf_to_compare].compare(\n",
    "    qfs[second_qf_to_compare],\n",
    "    label_self=(\n",
    "        f\"Mu = {round(mus[first_qf_to_compare], 2)}, \"\n",
    "        f\"Sigma = {round(sigmas[first_qf_to_compare], 2)}\"\n",
    "    ),\n",
    "    label_other=(\n",
    "        f\"Mu = {round(mus[second_qf_to_compare], 2)}, \"\n",
    "        f\"Sigma = {round(sigmas[second_qf_to_compare], 2)}\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot some densities of the generated distributions\n",
    "fig, ax = plt.subplots()\n",
    "some_qfs = np.random.default_rng().choice(qfs, size=6, replace=False)\n",
    "for qf in some_qfs:\n",
    "    pdf = qf.invert().differentiate()\n",
    "    ax.plot(\n",
    "        pdf.x,\n",
    "        pdf.y,\n",
    "    )\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimates = solve_frechet_qp(\n",
    "    xs_to_predict=x_grid, x_observed=predictor_vals, quantile_functions=qfs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for qf in estimates:\n",
    "    pdf = qf.invert().differentiate()\n",
    "    plt.plot(pdf.x, pdf.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a 2D array to hold f(u, x) values\n",
    "z_values = np.zeros((len(x_grid), len(estimates[0].x)))\n",
    "\n",
    "# Populate the array with estimates\n",
    "for i, func in enumerate(estimates):\n",
    "    z_values[i] = func.y\n",
    "\n",
    "# Create the 3D surface plot\n",
    "X, Y = np.meshgrid(estimates[0].x, x_grid)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.plot_surface(X, Y, z_values, cmap=\"viridis\", alpha=0.9)\n",
    "\n",
    "# Adjust the viewing angle for better visibility\n",
    "ax.view_init(elev=15, azim=245)\n",
    "\n",
    "ax.set_xlabel(\"u\")\n",
    "ax.set_ylabel(\"Predictor x\")\n",
    "ax.set_zlabel(\"Q(u | x)\", rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose qfs of interest\n",
    "mus_to_compare, sigmas_to_compare = gen_params_regression(\n",
    "    mu_params_dict, sigma_params_dict, x_grid, seed,\n",
    ")\n",
    "qfs_of_interest = gen_y_qf(mus_to_compare, sigmas_to_compare, u)\n",
    "qfs_of_interest = [qf.drop_inf() for qf in qfs_of_interest]\n",
    "# New z_values for 'qfs'\n",
    "z_values_qfs_subset = np.zeros((len(x_grid), len(qfs_of_interest[0].x)))\n",
    "for i, func in enumerate(qfs_of_interest):\n",
    "    z_values_qfs_subset[i] = func.y\n",
    "\n",
    "# Create the 3D surface plot for 'estimates'\n",
    "X, Y = np.meshgrid(qfs_of_interest[0].x, x_grid)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# Create the 3D surface plot for 'qfs'\n",
    "ax.plot_surface(X, Y, z_values_qfs_subset, cmap=\"magma\", alpha=0.9)\n",
    "\n",
    "# Adjust the viewing angle for better visibility\n",
    "ax.view_init(elev=15, azim=240)\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel(\"u\")\n",
    "ax.set_ylabel(\"Predictor x\")\n",
    "ax.set_zlabel(\"Q(u | x)\", rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot for all qfs, not just subset\n",
    "z_values_qfs = np.zeros((len(predictor_vals), len(qfs[0].x)))\n",
    "for i, func in enumerate(qfs):\n",
    "    z_values_qfs[i] = func.y\n",
    "\n",
    "# Create the 3D surface plot for 'estimates'\n",
    "X, Y = np.meshgrid(qfs[0].x, predictor_vals)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# Create the 3D surface plot for 'qfs'\n",
    "ax.plot_surface(X, Y, z_values_qfs, cmap=\"magma\", alpha=0.7)\n",
    "\n",
    "# Adjust the viewing angle for better visibility\n",
    "ax.view_init(elev=15, azim=240)\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel(\"u\")\n",
    "ax.set_ylabel(\"Predictor x\")\n",
    "ax.set_zlabel(\"Q(u | x)\", rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 3D surface plot for 'estimates'\n",
    "X, Y = np.meshgrid(qfs_of_interest[0].x, x_grid)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.plot_surface(X, Y, z_values, cmap=\"viridis\", alpha=0.7)\n",
    "\n",
    "# Create the 3D surface plot for 'qfs'\n",
    "ax.plot_surface(X, Y, z_values_qfs_subset, cmap=\"magma\", alpha=0.7)\n",
    "\n",
    "# Adjust the viewing angle for better visibility\n",
    "ax.view_init(elev=15, azim=190)\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel(\"u\")\n",
    "ax.set_ylabel(\"Predictor x\")\n",
    "ax.set_zlabel(\"Q(u | x)\", rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Integrated Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_hat = estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mus = mu_params_dict[\"mu0\"] + mu_params_dict[\"beta\"] * x_grid\n",
    "true_sigmas = sigma_params_dict[\"sigma0\"] + sigma_params_dict[\"gamma\"] * x_grid\n",
    "true_m = gen_y_qf(true_mus, true_sigmas, u)\n",
    "true_m = [qf.drop_inf() for qf in true_m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "differences = [hat - true for hat, true in zip(m_hat, true_m, strict=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ise_wasserstein(m_hat, true_m, x_grid, already_qf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Regression with Transformation method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see whether toying around with function and returning to it changes anything\n",
    "qfs[199].drop_inf().differentiate().integrate().compare(qfs[199].drop_inf() + 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdfs = [qf.drop_inf().invert().differentiate() for qf in qfs]\n",
    "lqdfs, start_vals = log_qd_transform(pdfs, different_supports=True)\n",
    "start_vals = np.array(start_vals, dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor_matrix = np.array((np.ones_like(predictor_vals), predictor_vals)).transpose()\n",
    "predictor_matrix.shape, np.linalg.inv(\n",
    "    predictor_matrix.transpose() @ predictor_matrix,\n",
    ").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_betahat = (\n",
    "    np.linalg.inv(predictor_matrix.transpose() @ predictor_matrix)\n",
    "    @ predictor_matrix.transpose()\n",
    "    @ lqdfs\n",
    ")\n",
    "log_betahat0 = log_betahat[0]\n",
    "log_betahat1 = log_betahat[1]\n",
    "log_betahat0.compare(log_betahat1, label_self=\"beta0\", label_other=\"beta1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See that beta0 is equal to the mean of the log qdfs\n",
    "mean_func(lqdfs).compare(\n",
    "    log_betahat0 + 0.05, label_self=\"Mean lqdf\", label_other=\"Beta_0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lqdf_hat = x_grid * log_betahat1 + log_betahat0\n",
    "interpolated_start_vals = np.interp(x_grid, predictor_vals, start_vals)\n",
    "pdf_hat = inverse_log_qd_transform(lqdf_hat, interpolated_start_vals)\n",
    "lqdfs[0].compare(lqdf_hat[0], label_self=\"Lqdf 0\", label_other=\"Estimated Lqdf 0\")\n",
    "lqdfs[49].compare(lqdf_hat[49], label_self=\"Lqdf 49\", label_other=\"Estimated Lqdf 49\")\n",
    "true_m[0].invert().differentiate().compare(\n",
    "    pdf_hat[0], label_self=\"Mean lqdf\", label_other=\"Beta_0\",\n",
    ")\n",
    "true_m[49].invert().differentiate().compare(\n",
    "    pdf_hat[49], label_self=\"Mean lqdf\", label_other=\"Beta_0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate integrated squared error\n",
    "qf_hat = [pdf.integrate().invert() for pdf in pdf_hat]\n",
    "ise_wasserstein(qf_hat, true_m, x_grid, already_qf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_of_interest = 20\n",
    "pdfs[distribution_of_interest].compare(pdf_hat[distribution_of_interest])\n",
    "qfs[distribution_of_interest].compare(\n",
    "    pdf_hat[distribution_of_interest].integrate().invert(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For demonstration of estimation effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, lqd in enumerate(lqdf_hat[::10]):\n",
    "    plt.plot(lqd.x, lqd.y, label=i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, qf in enumerate(qf_hat[::20]):\n",
    "    plt.plot(qf.x, qf.y, label=i)\n",
    "for i, qf in enumerate(true_m[::20]):\n",
    "    plt.plot(qf.x, qf.y, label=f\"True {i}\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pdf in enumerate(pdfs[::50]):\n",
    "    plt.plot(pdf.x, pdf.y, label=i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, pdf in enumerate(pdf_hat[::10]):\n",
    "    plt.plot(pdf.x, pdf.y, label=i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, qf in enumerate(estimates[::10]):\n",
    "    pdf = qf.invert().differentiate()\n",
    "    plt.plot(pdf.x, pdf.y, label=i)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New z_values for 'qfs'\n",
    "qf_hats_of_interest = [pdf.integrate().invert().drop_inf() for pdf in pdf_hat]\n",
    "z_values_pdf_hats = np.zeros((len(x_grid), len(qf_hats_of_interest[0].x)))\n",
    "for i, func in enumerate(qf_hats_of_interest):\n",
    "    z_values_pdf_hats[i] = func.y\n",
    "\n",
    "# Create the 3D surface plot for 'estimates'\n",
    "X, Y = np.meshgrid(qf_hats_of_interest[0].x, x_grid)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.plot_surface(X, Y, z_values, cmap=\"viridis\", alpha=0.7)\n",
    "\n",
    "# Create the 3D surface plot for 'qfs'\n",
    "ax.plot_surface(X, Y, z_values_pdf_hats, cmap=\"magma\", alpha=0.7)\n",
    "\n",
    "# Adjust the viewing angle for better visibility\n",
    "ax.view_init(elev=15, azim=245)\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel(\"u\")\n",
    "ax.set_ylabel(\"Predictor x\")\n",
    "ax.set_zlabel(\"Q(u | x)\", rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 3D surface plot for qfs\n",
    "X, Y = np.meshgrid(qf_hats_of_interest[0].x, x_grid)\n",
    "\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "ax.plot_surface(X, Y, z_values_qfs_subset, cmap=\"viridis\", alpha=0.7)\n",
    "\n",
    "# Create the 3D surface plot for functional regression estimates\n",
    "ax.plot_surface(X, Y, z_values_pdf_hats, cmap=\"magma\", alpha=0.7)\n",
    "\n",
    "# Adjust the viewing angle for better visibility\n",
    "ax.view_init(elev=15, azim=245)\n",
    "\n",
    "# Add labels\n",
    "ax.set_xlabel(\"u\")\n",
    "ax.set_ylabel(\"Predictor x\")\n",
    "ax.set_zlabel(\"Q(u | x)\", rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of simulations\n",
    "m = 500\n",
    "# Number of samples of densities to generate\n",
    "sample_sizes = [50, 100, 200]\n",
    "# Number of sample points to generate from each density for density estimation step\n",
    "points_number = 100\n",
    "# Which kernel to use in density estimation\n",
    "which_kernel = \"std_normal\"\n",
    "# Set interval within which to estimate densities, approx of -inf and inf\n",
    "denstimation_limits = (-30, 30)\n",
    "# Fineness of grids to evaluate functions\n",
    "grid_size = 500\n",
    "delta = 0  # can start bounded away from zero and one\n",
    "u = np.linspace(delta, 1 - delta, grid_size)\n",
    "\n",
    "# Choose for which x_vals to predict conditional quantiles (predicting at\n",
    "# every x from predictor_vals would be very computationally expensive)\n",
    "grid_to_predict_size = 50\n",
    "x_grid = np.linspace(-1, 1, grid_to_predict_size)\n",
    "\n",
    "# Parameters for stochastic process that generates conditional distributions\n",
    "predictor_bounds = (-1, 1)\n",
    "mu_params_dict = {\"mu0\": 0, \"beta\": 3, \"v1\": 0.25}\n",
    "sigma_params_dict = {\"sigma0\": 3, \"gamma\": 0.5, \"v2\": 2}\n",
    "# Calculate true stochastic process to compare later against estimates\n",
    "true_mus = mu_params_dict[\"mu0\"] + mu_params_dict[\"beta\"] * x_grid\n",
    "true_sigmas = sigma_params_dict[\"sigma0\"] + sigma_params_dict[\"gamma\"] * x_grid\n",
    "true_m = gen_y_qf(true_mus, true_sigmas, u)\n",
    "true_m = [qf.drop_inf() for qf in true_m]\n",
    "\n",
    "# For storing simulation results\n",
    "stored_ise_frechet = np.empty((m, len(sample_sizes)))\n",
    "stored_ise_func_reg = np.empty((m, len(sample_sizes)))\n",
    "stored_ise_frechet_denstimation = np.empty((m, len(sample_sizes)))\n",
    "stored_ise_func_reg_denstimation = np.empty((m, len(sample_sizes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_iterations = m * len(sample_sizes)  # Total iterations\n",
    "progress_bar = tqdm(total=total_iterations, desc=\"Simulation\")\n",
    "for i in range(m):\n",
    "    # Try different sample sizes\n",
    "    for j, n in enumerate(sample_sizes):\n",
    "        # j index only used for storing ISE values below!\n",
    "        # Set parameters\n",
    "        seed_num = int(str(i) + str(j))  # unique seed in each simulation run\n",
    "        predictor_vals = gen_predictor_values_regression(n, predictor_bounds, seed_num)\n",
    "        mus, sigmas = gen_params_regression(\n",
    "            mu_params_dict, sigma_params_dict, predictor_vals, seed_num,\n",
    "        )\n",
    "\n",
    "        # Generate conditional distributions\n",
    "        qfs = gen_y_qf(mus, sigmas, u)\n",
    "        qfs = [qf.drop_inf() for qf in qfs]\n",
    "        pdfs = [qf.invert().differentiate() for qf in qfs]\n",
    "\n",
    "        # Estimate conditional quantile function given x\n",
    "        m_hat = solve_frechet_qp(\n",
    "            xs_to_predict=x_grid, x_observed=predictor_vals, quantile_functions=qfs,\n",
    "        )\n",
    "\n",
    "        # Store estimation error\n",
    "        stored_ise_frechet[i, j] = ise_wasserstein(\n",
    "            m_hat, true_m, x_grid, already_qf=True,\n",
    "        )\n",
    "\n",
    "        ## Transformation method\n",
    "        lqdfs, start_vals = log_qd_transform(pdfs, different_supports=True)\n",
    "        start_vals = np.array(start_vals, dtype=np.float64)\n",
    "\n",
    "        # Calculate effect of x on lqdf\n",
    "        predictor_matrix = np.array(\n",
    "            (np.ones_like(predictor_vals), predictor_vals),\n",
    "        ).transpose()\n",
    "        log_betahat = (\n",
    "            np.linalg.inv(predictor_matrix.transpose() @ predictor_matrix)\n",
    "            @ predictor_matrix.transpose()\n",
    "            @ lqdfs\n",
    "        )\n",
    "\n",
    "        # Estimated lqdfs and their inverse transforms\n",
    "        lqdf_hat = x_grid * log_betahat[1] + log_betahat[0]\n",
    "        interpolated_start_vals = np.interp(x_grid, predictor_vals, start_vals)\n",
    "        pdf_hat = inverse_log_qd_transform(lqdf_hat, interpolated_start_vals)\n",
    "        qf_hat = [pdf.integrate().invert() for pdf in pdf_hat]\n",
    "\n",
    "        # Store estimation error\n",
    "        stored_ise_func_reg[i, j] = ise_wasserstein(\n",
    "            qf_hat, true_m, x_grid, already_qf=True,\n",
    "        )\n",
    "\n",
    "        ### With density estimation\n",
    "        sample_points = gen_sample_points_from_qfs(qfs, points_number, seed_num)\n",
    "\n",
    "        # Density estimation\n",
    "        # Rule-of-Thumb bandwidth (Li and Racine 2007, p. 66)\n",
    "        bandwidth = 1.06 * np.std(sample_points, axis=0) * (n ** (-0.2))\n",
    "        temp_estimated_pdfs = make_estimated_pdf(\n",
    "            sample_points=sample_points,\n",
    "            a=denstimation_limits[0] * np.ones(n),\n",
    "            b=denstimation_limits[1] * np.ones(n),\n",
    "            kern=which_kernel,\n",
    "            grid_size=grid_size,\n",
    "            bandwidth=bandwidth,\n",
    "            bias_corrected=False,\n",
    "        )\n",
    "        # Get actual support\n",
    "        new_ranges = get_optimal_range(temp_estimated_pdfs)\n",
    "        # Generate numerically stable objects, within individual ranges\n",
    "        estimated_pdfs = make_estimated_pdf(\n",
    "            sample_points=sample_points,\n",
    "            a=new_ranges[:, 0],\n",
    "            b=new_ranges[:, 1],\n",
    "            kern=which_kernel,\n",
    "            grid_size=grid_size,\n",
    "            bandwidth=bandwidth,\n",
    "            bias_corrected=False,\n",
    "        )\n",
    "        estimated_qfs = [pdf.integrate().invert() for pdf in estimated_pdfs]\n",
    "\n",
    "        # Estimate conditional quantile function given x\n",
    "        m_hat = solve_frechet_qp(\n",
    "            xs_to_predict=x_grid,\n",
    "            x_observed=predictor_vals,\n",
    "            quantile_functions=estimated_qfs,\n",
    "        )\n",
    "\n",
    "        # Store estimation error\n",
    "        stored_ise_frechet_denstimation[i, j] = ise_wasserstein(\n",
    "            m_hat, true_m, x_grid, already_qf=True,\n",
    "        )\n",
    "\n",
    "        ## Transformation method\n",
    "        estimated_lqdfs, start_vals = log_qd_transform(\n",
    "            estimated_pdfs, different_supports=True,\n",
    "        )\n",
    "        start_vals = np.array(start_vals, dtype=np.float64)\n",
    "\n",
    "        # Calculate effect of x on lqdf\n",
    "        predictor_matrix = np.array(\n",
    "            (np.ones_like(predictor_vals), predictor_vals),\n",
    "        ).transpose()\n",
    "        log_betahat = (\n",
    "            np.linalg.inv(predictor_matrix.transpose() @ predictor_matrix)\n",
    "            @ predictor_matrix.transpose()\n",
    "            @ estimated_lqdfs\n",
    "        )\n",
    "\n",
    "        # Estimated lqdfs and their inverse transforms\n",
    "        lqdf_hat = x_grid * log_betahat[1] + log_betahat[0]\n",
    "        interpolated_start_vals = np.interp(x_grid, predictor_vals, start_vals)\n",
    "        pdf_hat = inverse_log_qd_transform(lqdf_hat, interpolated_start_vals)\n",
    "        qf_hat = [pdf.integrate().invert() for pdf in pdf_hat]\n",
    "\n",
    "        # Store estimation error\n",
    "        stored_ise_func_reg_denstimation[i, j] = ise_wasserstein(\n",
    "            qf_hat, true_m, x_grid, already_qf=True,\n",
    "        )\n",
    "\n",
    "        # Print progress of simulation\n",
    "        progress_bar.update()\n",
    "progress_bar.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results if large simulation was run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if m > 100:\n",
    "    # Create a dictionary to hold all arrays\n",
    "    data_dict = {\n",
    "        \"stored_ise_frechet\": stored_ise_frechet,\n",
    "        \"stored_ise_func_reg\": stored_ise_func_reg,\n",
    "        \"stored_ise_frechet_denstimation\": stored_ise_frechet_denstimation,\n",
    "        \"stored_ise_func_reg_denstimation\": stored_ise_func_reg_denstimation,\n",
    "    }\n",
    "\n",
    "    # Save the dictionary using pickle\n",
    "    file_path_pickle = SRC / \"sim_results\" / \"stored_ise_arrays.pkl\"\n",
    "\n",
    "    with open(file_path_pickle, \"wb\") as handle:\n",
    "        pickle.dump(data_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    np.mean(stored_ise_frechet, axis=0),\n",
    "    np.mean(stored_ise_func_reg, axis=0),\n",
    "    np.mean(stored_ise_frechet_denstimation, axis=0),\n",
    "    np.mean(stored_ise_func_reg_denstimation, axis=0),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(stored_ise_frechet, labels=[\"50\", \"100\", \"200\"])\n",
    "\n",
    "plt.title(\"Distribution of ISE Across Different Sample Sizes\")\n",
    "plt.xlabel(\"Sample Size\")\n",
    "plt.ylabel(\"Integrated Squared Error (ISE)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(stored_ise_func_reg, labels=[\"50\", \"100\", \"200\"])\n",
    "\n",
    "plt.title(\"Distribution of ISE Across Different Sample Sizes\")\n",
    "plt.xlabel(\"Sample Size\")\n",
    "plt.ylabel(\"Integrated Squared Error (ISE)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(stored_ise_frechet_denstimation, labels=[\"50\", \"100\", \"200\"])\n",
    "\n",
    "plt.title(\"Distribution of ISE Across Different Sample Sizes\")\n",
    "plt.xlabel(\"Sample Size\")\n",
    "plt.ylabel(\"Integrated Squared Error (ISE)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(stored_ise_func_reg_denstimation, labels=[\"50\", \"100\", \"200\"])\n",
    "\n",
    "plt.title(\"Distribution of ISE Across Different Sample Sizes\")\n",
    "plt.xlabel(\"Sample Size\")\n",
    "plt.ylabel(\"Integrated Squared Error (ISE)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without density estimation step, unclear effect of increasing sample size; error decreases\n",
    "from 50 to 100 for both methods, but increases from 100 to 200. Maybe here numerical\n",
    "inacurracies dominate, while error when density estimation is included is mainly driven\n",
    "from having to estimate densities. They profit from having more densities observed?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "frechet_fda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
