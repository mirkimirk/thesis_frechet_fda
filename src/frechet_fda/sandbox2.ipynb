{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sandbox module.\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from misc import l2_norm, riemann_sum, riemann_sum_arrays\n",
    "from scipy.stats import norm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\int_0^1 f(t)dt$  wird dann durch die Riemann Summe $1/m \\sum_{j=1}^m f(s_j)$ ersetzt ($s_j$  - Gridpunkte, $m$ -  Anzahl der Gridpunkte)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional Data Analysis\n",
    "\n",
    "Ideas for simulation\n",
    "- Uni- vs. Multivariate case\n",
    "- Simulate different normal distributions\n",
    "- Vary parameters of (generalized) Beta distribution, so principal components can be interpreted as varying parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X(t) = \\sum_{k=1}^n η_k φ_k(t)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation Method Paper (Petersen & Müller 2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define normal density\n",
    "def norm_density(x, mu, sigma):\n",
    "    \"\"\"Define normal density function.\n",
    "\n",
    "    To test: columns of x must align with mu and sigma.\n",
    "    \"\"\"\n",
    "    x = np.array(x)  # to vectorize the input\n",
    "    mu = np.array(mu)\n",
    "    sigma = np.array(sigma)\n",
    "    return np.reciprocal(np.sqrt(2 * np.pi) * sigma) * np.exp(\n",
    "        (-0.5) * ((x - mu) / sigma) ** 2,\n",
    "    )\n",
    "\n",
    "\n",
    "def norm_cdf(x, mu, sigma, m):\n",
    "    \"\"\"Compute the CDF of the normal distribution at a given point x.\"\"\"\n",
    "    a = -10  # Lower limit of integration (approximation of negative infinity)\n",
    "    b = x  # Upper limit of integration\n",
    "    # Integrate the normal density function from a to b\n",
    "    return riemann_sum(a, b, m, lambda y: norm_density(y, mu, sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate synthetic functional data\n",
    "n = 200\n",
    "gridnum = 1000\n",
    "endpoint_densities = 5\n",
    "grid_densities = np.linspace(\n",
    "    start=-np.ones(n) * endpoint_densities,\n",
    "    stop=np.ones(n) * endpoint_densities,\n",
    "    num=gridnum,\n",
    ")\n",
    "grid_quantiles = np.linspace(\n",
    "    start=np.ones(n) * 0.01,\n",
    "    stop=np.ones(n) * 0.99,\n",
    "    num=gridnum,\n",
    ")\n",
    "grid_densities_univ = np.linspace(\n",
    "    start=-endpoint_densities,\n",
    "    stop=endpoint_densities,\n",
    "    num=gridnum,\n",
    ")\n",
    "grid_quantiles_univ = np.linspace(start=0, stop=1, num=gridnum)\n",
    "\n",
    "# Draw different sigmas\n",
    "log_sigmas = np.random.default_rng(seed=28071995).uniform(-1.5, 1.5, n)\n",
    "mus = np.zeros(n)\n",
    "sigmas = np.exp(log_sigmas)\n",
    "densities_discretized = norm_density(grid_densities, mus, sigmas).transpose()\n",
    "quantiles_discretized = norm.ppf(grid_quantiles, mus, sigmas).transpose()\n",
    "quantile_densities_discretized = np.reciprocal(\n",
    "    norm_density(norm.ppf(grid_quantiles, mus, sigmas), mus, sigmas),\n",
    ").transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Compute the mean function\n",
    "mean_function = np.mean(densities_discretized, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Center the data\n",
    "centered_densities = densities_discretized - mean_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Estimate the covariance function using a discrete approximation\n",
    "cov_matrix = np.cov(centered_densities, rowvar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Compute the eigenfunctions (principal components) of the covariance matrix\n",
    "eigenvalues, eigenfunctions = np.linalg.eigh(cov_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort eigenvalues and eigenfunctions in decreasing order\n",
    "eigenvalues_sorted = eigenvalues[np.argsort(-eigenvalues)]\n",
    "eigenfunctions_sorted = eigenfunctions[:, np.argsort(-eigenvalues)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Adjust the lambda function to handle array input and interpolate values from the\n",
    "# eigenvector\n",
    "\n",
    "# Compute the L^2 norm for each column (eigenvector) for rescaling to l2 norm\n",
    "l2_norms = l2_norm(\n",
    "    left_bound_support=-endpoint_densities,\n",
    "    right_bound_support=endpoint_densities,\n",
    "    array=eigenfunctions_sorted,\n",
    "    axis=0,\n",
    ")\n",
    "\n",
    "# Scale each column of the eigenfunctions matrix by its respective L^2 norm using\n",
    "# broadcasting\n",
    "eigenfunctions_scaled = eigenfunctions_sorted / l2_norms\n",
    "\n",
    "# Check the first few L^2 norms to verify\n",
    "first_few_norms = l2_norm(\n",
    "    left_bound_support=-endpoint_densities,\n",
    "    right_bound_support=endpoint_densities,\n",
    "    array=eigenfunctions_scaled,\n",
    "    axis=0,\n",
    ")\n",
    "first_few_norms[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Compute FPC scores / factor loadings\n",
    "products = np.einsum(\"ij,jk->ijk\", centered_densities, eigenfunctions_scaled)\n",
    "fpc_scores = riemann_sum_arrays(\n",
    "    left_bound=-endpoint_densities,\n",
    "    right_bound=endpoint_densities,\n",
    "    multi_dim_array=products,\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the mean function and the first two eigenfunctions\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.plot(grid_densities_univ, mean_function, \"b-\")\n",
    "plt.title(\"Mean Function\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.plot(grid_densities_univ, eigenfunctions_sorted[:, 0], \"r-\")\n",
    "plt.title(\"1st Eigenfunction\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.plot(grid_densities_univ, eigenfunctions_sorted[:, 1], \"g-\")\n",
    "plt.title(\"2nd Eigenfunction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More reproducing of Petersen & Müller (2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fve(k):\n",
    "    \"\"\"Compute explained variance.\"\"\"\n",
    "    return np.sum(eigenvalues_sorted[0:k]) / np.sum(eigenvalues_sorted)\n",
    "\n",
    "\n",
    "fve(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_of_variation(alpha, mean_func, eigval, eigfunc):\n",
    "    \"\"\"Compute kth mode of variation.\"\"\"\n",
    "    return mean_func + alpha * np.sqrt(eigval) * eigfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_mode = mode_of_variation(\n",
    "    1,\n",
    "    mean_function,\n",
    "    eigenvalues_sorted[0],\n",
    "    eigenfunctions_sorted[:, 0],\n",
    ")\n",
    "second_mode = mode_of_variation(\n",
    "    1,\n",
    "    mean_function,\n",
    "    eigenvalues_sorted[1],\n",
    "    eigenfunctions_sorted[:, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(grid_densities_univ, mean_function, label=\"Mean function\")\n",
    "ax.plot(grid_densities_univ, first_mode, label=\"First mode\")\n",
    "ax.plot(grid_densities_univ, second_mode, label=\"Second mode\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_qdf = np.mean(quantile_densities_discretized, axis=0)\n",
    "plt.plot(grid_quantiles_univ, mean_qdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_qdf_interpolator(x):\n",
    "    \"\"\"Compute mean_qdf at any point.\"\"\"\n",
    "    return np.interp(x, grid_quantiles_univ, mean_qdf)\n",
    "\n",
    "\n",
    "def wf_mean(x, mu, sigma, m):\n",
    "    \"\"\"Wasserstein-Fréchet mean function.\"\"\"\n",
    "    return np.reciprocal(mean_qdf_interpolator(norm_cdf(x, mu, sigma, m)))\n",
    "\n",
    "\n",
    "wf_mean(0, mu=mus[0], sigma=sigmas[0], m=50000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(grid_densities_univ, -eigenfunctions_sorted[:, 0], label=\"First component\")\n",
    "ax.plot(grid_densities_univ, -eigenfunctions_sorted[:, 1], label=\"Second component\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
