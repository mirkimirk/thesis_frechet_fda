{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from frechet_fda.data_generation_tools import (\n",
    "    gen_params_scenario_one,\n",
    "    make_truncnorm_pdf,\n",
    ")\n",
    "from frechet_fda.distribution_tools import (\n",
    "    frechet_mean,\n",
    "    get_optimal_range,\n",
    "    inverse_log_qd_transform,\n",
    "    log_qd_transform,\n",
    "    make_distribution_objects,\n",
    "    mean_func,\n",
    ")\n",
    "from frechet_fda.fda_tools import (\n",
    "    compute_centered_data,\n",
    "    compute_cov_function,\n",
    "    compute_principal_components,\n",
    "    gen_qdtransformation_pcs,\n",
    "    k_optimal,\n",
    "    karhunen_loeve,\n",
    "    mode_of_variation,\n",
    "    total_frechet_variance,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "n = 200\n",
    "grid_size = 10000\n",
    "trunc = 3\n",
    "mus, sigmas = gen_params_scenario_one(n)\n",
    "# Sort sigmas, because when summing Distribution instances something goes wrong otherwise\n",
    "sigmas.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate pdfs within truncation points\n",
    "pdfs = make_truncnorm_pdf(-trunc, trunc, mus, sigmas, grid_size=grid_size)\n",
    "# Make Distribution class objects\n",
    "my_pdfs = make_distribution_objects(pdfs)\n",
    "my_cdfs = [pdf.integrate() for pdf in my_pdfs]\n",
    "my_qfs = [cdf.invert() for cdf in my_cdfs]\n",
    "my_qdfs = [qf.differentiate() for qf in my_qfs]\n",
    "# For numerical correction: shorten the range for smaller sigmas to get rid of\n",
    "# numerical artifacts when computing integrals, derivatives and means later\n",
    "new_ranges = get_optimal_range(my_pdfs)\n",
    "# Generate pdfs again, this time within individual ranges\n",
    "pdfs2 = [\n",
    "    make_truncnorm_pdf(\n",
    "        new_ranges[i][0],\n",
    "        new_ranges[i][1],\n",
    "        mus[i],\n",
    "        sigmas[i],\n",
    "        grid_size=grid_size,\n",
    "    )[0]\n",
    "    for i in range(n)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all the distribution objects\n",
    "new_pdfs = make_distribution_objects(pdfs2)\n",
    "new_cdfs = [pdf.integrate() for pdf in new_pdfs]\n",
    "new_qfs = [cdf.invert() for cdf in new_cdfs]\n",
    "new_qdfs = [qf.differentiate() for qf in new_qfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute centered data, just to see whether it works\n",
    "# One can clearly see how inappropriate it is to apply fda methods on densities\n",
    "mean_pdf, centered_pdfs = compute_centered_data(new_pdfs)\n",
    "centered_pdfs[sigmas.argmin()].compare(new_pdfs[sigmas.argmin()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance_function = compute_cov_function(centered_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eigenvalues, eigenfunctions = compute_principal_components(\n",
    "    centered_pdfs[0].x,\n",
    "    covariance_function,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformation FPCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform pdf sample, and test whether inverse works\n",
    "log_qdfs = log_qd_transform(new_pdfs)\n",
    "inverse_log_qdfs = inverse_log_qd_transform(log_qdfs)\n",
    "inverse_log_qdfs[0].compare(new_pdfs[0] + 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute transformation FPCA objects\n",
    "(\n",
    "    mean_log_qdfs,\n",
    "    eigenvalues_log_qdfs,\n",
    "    eigenfunctions_log_qdfs,\n",
    "    fpc_scores_log_qdfs,\n",
    ") = gen_qdtransformation_pcs(log_qdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Karhunen-Loève decomposition of transforms\n",
    "truncated_representations_transforms = karhunen_loeve(\n",
    "    mean_log_qdfs,\n",
    "    eigenfunctions_log_qdfs,\n",
    "    fpc_scores_log_qdfs,\n",
    "    K=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform to density space\n",
    "truncated_representations = inverse_log_qd_transform(\n",
    "    truncated_representations_transforms,\n",
    ")\n",
    "truncated_representations[0].compare(new_pdfs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at modes of variance of transformed functions\n",
    "variation_modes_transforms = [\n",
    "    mode_of_variation(mean_log_qdfs, eigval, eigfunc, alpha=5e-3)\n",
    "    for eigval, eigfunc in zip(eigenvalues_log_qdfs, eigenfunctions_log_qdfs)\n",
    "]\n",
    "variation_modes_transforms[0].compare(variation_modes_transforms[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate modes of variation to density space, compare first two modes\n",
    "variation_modes = inverse_log_qd_transform(variation_modes_transforms)\n",
    "variation_modes[0].compare(variation_modes[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Fréchet mean\n",
    "f_mean = frechet_mean(new_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Fréchet variance\n",
    "total_variance = total_frechet_variance(f_mean, new_pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try function that finds optimal trunc representation\n",
    "optimal_k, fraction_explained, truncated_representations = k_optimal(\n",
    "    0.5,\n",
    "    total_variance,\n",
    "    new_pdfs,\n",
    "    mean_log_qdfs,\n",
    "    eigenfunctions_log_qdfs,\n",
    "    fpc_scores_log_qdfs,\n",
    ")\n",
    "optimal_k, fraction_explained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of simulations\n",
    "m = 3\n",
    "sample_sizes = [50, 100, 200]\n",
    "# Initialize arrays to store Fréchet and cross sectional means\n",
    "stored_f_means = np.empty((m, len(sample_sizes)), dtype=\"object\")\n",
    "stored_cs_means = np.empty((m, len(sample_sizes)), dtype=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Simulating...\", end=\"\\r\")\n",
    "for i in range(m):\n",
    "    # Try different sample sizes\n",
    "    for j, n in enumerate(sample_sizes):\n",
    "        # j index only used for storing Fréchet means below!\n",
    "        # Set parameters\n",
    "        grid_size = 10000\n",
    "        trunc = 3\n",
    "        seed_num = int(str(i) + str(n))\n",
    "        mus, sigmas = gen_params_scenario_one(n, seed=seed_num)\n",
    "        # Sort sigmas, because when summing Distribution instances something goes wrong otherwise\n",
    "        sigmas.sort()\n",
    "\n",
    "        # Generate pdfs within truncation points\n",
    "        pdfs = make_truncnorm_pdf(-trunc, trunc, mus, sigmas, grid_size=grid_size)\n",
    "        # Make Distribution class objects\n",
    "        my_pdfs = make_distribution_objects(pdfs)\n",
    "        my_cdfs = [pdf.integrate() for pdf in my_pdfs]\n",
    "        my_qfs = [cdf.invert() for cdf in my_cdfs]\n",
    "        my_qdfs = [qf.differentiate() for qf in my_qfs]\n",
    "        # For numerical correction: shorten the range for smaller sigmas to get rid of\n",
    "        # numerical artifacts when computing integrals, derivatives and means later\n",
    "        new_ranges = get_optimal_range(my_pdfs)\n",
    "        # Generate pdfs again, this time within individual ranges\n",
    "        pdfs2 = [\n",
    "            make_truncnorm_pdf(\n",
    "                new_ranges[i][0],\n",
    "                new_ranges[i][1],\n",
    "                mus[i],\n",
    "                sigmas[i],\n",
    "                grid_size=grid_size,\n",
    "            )[0]\n",
    "            for i in range(n)\n",
    "        ]\n",
    "\n",
    "        # Generate all the distribution objects\n",
    "        new_pdfs = make_distribution_objects(pdfs2)\n",
    "        new_cdfs = [pdf.integrate() for pdf in new_pdfs]\n",
    "        new_qfs = [cdf.invert() for cdf in new_cdfs]\n",
    "        new_qdfs = [qf.differentiate() for qf in new_qfs]\n",
    "\n",
    "        # Transform pdf sample\n",
    "        log_qdfs = log_qd_transform(new_pdfs)\n",
    "\n",
    "        (\n",
    "            mean_log_qdfs,\n",
    "            eigenvalues_log_qdfs,\n",
    "            eigenfunctions_log_qdfs,\n",
    "            fpc_scores_log_qdfs,\n",
    "        ) = gen_qdtransformation_pcs(log_qdfs)\n",
    "\n",
    "        # Compute Fréchet mean\n",
    "        stored_f_means[i, j] = frechet_mean(new_pdfs)\n",
    "        stored_cs_means[i, j] = mean_func(new_pdfs)\n",
    "\n",
    "        # Compute Fréchet variance\n",
    "        total_variance = total_frechet_variance(f_mean, new_pdfs)\n",
    "        # # Try function that finds optimal trunc representation\n",
    "        optimal_k, fraction_explained, truncated_representations = k_optimal(\n",
    "            0.5,\n",
    "            total_variance,\n",
    "            new_pdfs,\n",
    "            mean_log_qdfs,\n",
    "            eigenfunctions_log_qdfs,\n",
    "            fpc_scores_log_qdfs,\n",
    "        )\n",
    "    perc = int(100 * (i + 1) / m)\n",
    "    print(f\"Simulating...{perc}%\", end=\"\\r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate true center of distribution for plotting against estimates\n",
    "std_normal = make_truncnorm_pdf(-trunc, trunc, 0, 1, grid_size=grid_size)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Fréchet means of Fréchet means over all simulations\n",
    "mean_of_f_means50 = frechet_mean(stored_f_means[:, 0])\n",
    "mean_of_f_means100 = frechet_mean(stored_f_means[:, 1])\n",
    "mean_of_f_means200 = frechet_mean(stored_f_means[:, 2])\n",
    "mean_of_cs_means50 = frechet_mean(stored_cs_means[:, 0])\n",
    "mean_of_cs_means100 = frechet_mean(stored_cs_means[:, 1])\n",
    "mean_of_cs_means200 = frechet_mean(stored_cs_means[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Fréchet means of different sample sizes against true center\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mean_of_f_means50.x, mean_of_f_means50.y, label=\"f-mean 50\", linestyle=\"--\")\n",
    "ax.plot(mean_of_f_means100.x, mean_of_f_means100.y, label=\"f-mean 100\", linestyle=\"--\")\n",
    "ax.plot(mean_of_f_means200.x, mean_of_f_means200.y, label=\"f-mean 200\", linestyle=\"--\")\n",
    "ax.plot(std_normal[0], std_normal[1], label=\"Standard Normal\", color=\"Black\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Fréchet means of different sample sizes against true center\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(mean_of_f_means200.x, mean_of_f_means200.y, label=\"f-mean 200\", linestyle=\"--\")\n",
    "ax.plot(\n",
    "    mean_of_cs_means200.x,\n",
    "    mean_of_cs_means200.y,\n",
    "    label=\"cs-mean 200\",\n",
    "    linestyle=\"--\",\n",
    ")\n",
    "ax.plot(std_normal[0], std_normal[1], label=\"Standard Normal\", color=\"black\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
