{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Sandbox module.\"\"\"\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from data_generation import gen_discretized_distributions, gen_grids_and_parameters\n",
    "from fda_funcs import (\n",
    "    compute_moments,\n",
    ")\n",
    "from misc import (\n",
    "    cdf_from_density,\n",
    "    dens_from_qd,\n",
    "    norm_cdf,\n",
    "    norm_pdf,\n",
    "    quantile_from_cdf,\n",
    "    riemann_sum_arrays,\n",
    "    trunc_norm_pdf,\n",
    ")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FrÃ©chet mean estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_grids_and_parameters(n, gridnum, truncation_point, delta):\n",
    "    \"\"\"Generate parameters for the density samples and define appropriate grids.\"\"\"\n",
    "    grid_densities = np.linspace(\n",
    "        start=-truncation_point,\n",
    "        stop=truncation_point,\n",
    "        num=gridnum,\n",
    "    )\n",
    "    grid_quantiles = np.linspace(start=delta, stop=1 - delta, num=gridnum)\n",
    "\n",
    "    # Draw different sigmas\n",
    "    log_sigmas = np.random.default_rng(seed=28071995).uniform(-1.5, 1.5, n)\n",
    "    mus = np.zeros(n)\n",
    "    sigmas = np.exp(log_sigmas)\n",
    "\n",
    "    return (grid_densities, grid_quantiles, mus, sigmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_discretized_distributions(grid_pdfs, grid_qfs, mus, sigmas, truncation_point):\n",
    "    \"\"\"Generate discretized pdfs, cdfs, qfs, and qdfs.\"\"\"\n",
    "    # Truncated pdfs\n",
    "    pdfs_discretized = trunc_norm_pdf(\n",
    "        grid_pdfs[:, np.newaxis],\n",
    "        mus,\n",
    "        sigmas,\n",
    "        -truncation_point,\n",
    "        truncation_point,\n",
    "    )\n",
    "\n",
    "    # Truncated cdfs\n",
    "    cdfs_discretized = cdf_from_density(\n",
    "        grid_pdfs,\n",
    "        pdfs_discretized,\n",
    "        axis=-1,\n",
    "    )\n",
    "\n",
    "    # Truncated qfs\n",
    "    qfs_discretized = quantile_from_cdf(\n",
    "        grid_pdfs[:, np.newaxis].transpose(),\n",
    "        cdfs_discretized,\n",
    "        grid_qfs,\n",
    "    )\n",
    "\n",
    "    # Truncated qdfs\n",
    "    qdfs_discretized = qd_from_dens(pdfs_discretized, dsup=grid_pdfs, qdsup=grid_qfs)\n",
    "\n",
    "    return pdfs_discretized, cdfs_discretized, qfs_discretized, qdfs_discretized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def riemann_sum_arrays(support_grid, array, axis=-1, cumsum=False):\n",
    "    \"\"\"Computes Riemann sum for given array, along the axis that contains the grid of\n",
    "    values.\n",
    "    \"\"\"\n",
    "    # Calculate the step size between consecutive grid points\n",
    "    step_sizes = np.diff(support_grid)\n",
    "    # Repeat last element so the output is not one element shorter. Should be approx.\n",
    "    # ok\n",
    "    step_sizes = np.append(step_sizes, step_sizes[..., -1][..., np.newaxis], axis=-1)\n",
    "\n",
    "    # Compute the cumulative sum along the specified axis (i.e.,\n",
    "    # the integral up to each grid point)\n",
    "    if cumsum:\n",
    "        result = np.cumsum(array * step_sizes, axis=axis)\n",
    "    else:\n",
    "        result = np.sum(array * step_sizes, axis=axis)\n",
    "\n",
    "    # Return the cumulative sums, which represent the CDF at each grid point\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qd_from_dens(dens, dsup=None, qdsup=None):\n",
    "    \"\"\"Compute quantile densities directly from densities.\n",
    "\n",
    "    'Inspired' from dens2qd in fdadensity package in R.\n",
    "    \"\"\"\n",
    "    # Validate input\n",
    "    eps = 1e-5\n",
    "    if not np.allclose([np.min(qdsup), np.max(qdsup)], [0, 1], atol=eps):\n",
    "        print([np.min(qdsup), np.max(qdsup)])\n",
    "        msg = \"Please check the support of the QF domain's boundaries.\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    integral_dens = riemann_sum_arrays(dsup, array=dens, axis=-1, cumsum=False)\n",
    "    deviations_from_1 = abs(integral_dens - 1)\n",
    "    if np.any(deviations_from_1 > eps):\n",
    "        warnings.warn(\n",
    "            f\"Not all provided densities integrate to 1 with tolerance {eps}!\"\n",
    "            f\"\\n Max case of deviation is: {deviations_from_1.max()} \"\n",
    "            f\"\\n In position: {deviations_from_1.argmax()} \"\n",
    "            \"\\n Performing normalization...\",\n",
    "        )\n",
    "        dens /=  integral_dens[..., np.newaxis]\n",
    "\n",
    "    qd = 1 / dens\n",
    "    integral_qd = riemann_sum_arrays(qdsup, qd, axis=-1, cumsum=False)\n",
    "    qd *= np.ptp(dsup) / integral_qd[..., np.newaxis]\n",
    "\n",
    "    return qd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trunc_norm_pdf(x, mu, sigma, a, b):\n",
    "    \"\"\"Define truncated normal density function.\n",
    "\n",
    "    To test: columns of x must align with mu and sigma.\n",
    "\n",
    "    \"\"\"\n",
    "    x = np.array(x)  # to vectorize the input\n",
    "    mu = np.array(mu)\n",
    "    sigma = np.array(sigma)\n",
    "    x_std = (x - mu) / sigma\n",
    "    a_std = (a - mu) / sigma\n",
    "    b_std = (b - mu) / sigma\n",
    "    numerator = norm_pdf(x_std, 0, 1)\n",
    "    denominator = norm_cdf(b_std, 0, 1) - norm_cdf(a_std, 0, 1)\n",
    "\n",
    "    result = numerator / denominator / sigma\n",
    "\n",
    "    # Create a boolean mask for values outside the interval [a, b]\n",
    "    mask = (x_std < a_std) | (x_std > b_std)\n",
    "\n",
    "    # Set the PDF to zero for values of x outside the interval [a, b]\n",
    "    result[mask] = 0\n",
    "    result = result.transpose()\n",
    "\n",
    "    # Check whether each density integrates to 1\n",
    "    eps = 1e-5\n",
    "    integrals = riemann_sum_arrays(np.linspace(a, b, len(x)), result, axis=-1)\n",
    "    deviations_from_1 = abs(integrals - 1)\n",
    "    if np.any(deviations_from_1 > eps):\n",
    "        warnings.warn(\n",
    "            f\"Not all provided densities integrate to 1 with tolerance {eps}!\"\n",
    "            f\"\\n Max case of deviation is: {deviations_from_1.max()} \"\n",
    "            f\"\\n In position: {deviations_from_1.argmax()} \"\n",
    "            \"\\n Performing normalization...\",\n",
    "        )\n",
    "        result /=  integrals[..., np.newaxis]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dens_from_qd(qds_discretized, qdsup=None, dsup=None):\n",
    "    \"\"\"Compute density from a quantile density function.\n",
    "\n",
    "    'Inspired' from qd2dens in fdadensity package in R.\n",
    "    \"\"\"\n",
    "    # Validate input\n",
    "    eps = 1e-5\n",
    "    if not np.allclose([np.min(qdsup), np.max(qdsup)], [0, 1], atol=eps):\n",
    "        print([np.min(qdsup), np.max(qdsup)])\n",
    "        msg = \"Please check the support of the qds_discretized domain's boundaries.\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    integral_qd = riemann_sum_arrays(qdsup, array=qds_discretized, axis=-1, cumsum=True)\n",
    "    if not np.isclose(integral_qd[-1], np.ptp(dsup), atol=eps):\n",
    "        print(integral_qd, np.ptp(dsup))\n",
    "        msg = \"Quantile Density does not integrate to the range of the densities with \"\n",
    "        f\"tolerance {eps}.\"\n",
    "        raise ValueError(msg)\n",
    "\n",
    "    # Calculate new support grid\n",
    "    dtemp = dsup[0] + integral_qd\n",
    "\n",
    "    # Calculate density\n",
    "    dens_temp = 1 / qds_discretized\n",
    "    dtemp, idx_unique = np.unique(dtemp, return_index=True, axis=-1)\n",
    "    dens_temp = dens_temp[idx_unique]\n",
    "    dens = np.interp(dsup, dtemp, dens_temp)\n",
    "\n",
    "    # Normalize the density\n",
    "    dens /= riemann_sum_arrays(dsup, dens, axis=-1, cumsum=False)[..., np.newaxis]\n",
    "\n",
    "    return dens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def density_from_qd_old(qds_discretized, dsup, qdsup=None):\n",
    "    \"\"\"Compute density from a quantile density function.\n",
    "\n",
    "    'Inspired' from qd2dens in fdadensity package in R.\n",
    "\n",
    "    \"\"\"\n",
    "    if qdsup is None:\n",
    "        qdsup = np.linspace(0, 1, len(qds_discretized))\n",
    "    quantile_oplus = dsup[0] + riemann_sum_arrays(\n",
    "        support_grid=qdsup, array=qds_discretized, axis=0, cumsum=True,\n",
    "    )\n",
    "\n",
    "    dens_temp = 1 / qds_discretized\n",
    "    ind = np.unique(quantile_oplus, return_index=True, axis=-1)[1]\n",
    "    quantile_oplus = np.atleast_1d(quantile_oplus)[ind]\n",
    "    dens_temp = dens_temp[~ind]\n",
    "    dens = np.interp(dsup, quantile_oplus, dens_temp)\n",
    "    dens /= riemann_sum_arrays(dsup, dens, axis=0, cumsum=False)[..., np.newaxis]\n",
    "\n",
    "    return dens, quantile_oplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wasserstein_frechet_mean(qds_discretized, dsup, qdsup=None):\n",
    "    \"\"\"Compute Wasserstein-FrÃ©chet mean from sample.\"\"\"\n",
    "    if qdsup is None:\n",
    "        qdsup = np.linspace(0, 1, qds_discretized.shape[-1])\n",
    "    mean_qdf = np.mean(qds_discretized, axis=0)\n",
    "    integral = riemann_sum_arrays(qdsup, array=mean_qdf, axis=-1, cumsum=False)\n",
    "    mean_qdf *= (dsup[-1] - dsup[0]) / integral\n",
    "    return dens_from_qd(mean_qdf, qdsup, dsup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data\n",
    "n = 200\n",
    "gridnum = 1000\n",
    "truncation_point = 3\n",
    "\n",
    "grid_pdfs1, grid_qfs1, mus1, sigmas1 = gen_grids_and_parameters(\n",
    "    n, gridnum, truncation_point, 0,\n",
    ")\n",
    "grid_pdfs2, grid_qfs2, mus2, sigmas2 = gen_grids_and_parameters(\n",
    "    n, gridnum, truncation_point, 1e-5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate distributions\n",
    "(\n",
    "    pdfs_discretized1,\n",
    "    cdfs_discretized1,\n",
    "    qfs_discretized1,\n",
    "    qdfs_discretized1,\n",
    ") = gen_discretized_distributions(\n",
    "    grid_pdfs1, grid_qfs1, mus1, sigmas1, truncation_point,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    pdfs_discretized2,\n",
    "    cdfs_discretized2,\n",
    "    qfs_discretized2,\n",
    "    qdfs_discretized2,\n",
    ") = gen_discretized_distributions(\n",
    "    grid_pdfs2, grid_qfs2, mus2, sigmas2, truncation_point,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempi = qd_from_dens(pdfs_discretized1, grid_pdfs1, grid_qfs1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempi.shape, qdfs_discretized1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lim1 = 999\n",
    "lim2 = 999\n",
    "integral1 = riemann_sum_arrays(grid_qfs1[:lim1], qdfs_discretized1[0][:lim1], axis=-1)\n",
    "integral2 = riemann_sum_arrays(grid_qfs1[:lim2], tempi[:lim2], axis=-1)\n",
    "integral1, integral2, grid_qfs1[lim1], grid_qfs2[lim2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_function1, centered_densities, cov_matrix = compute_moments(pdfs_discretized1)\n",
    "mean_function2, centered_densities, cov_matrix = compute_moments(pdfs_discretized2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whi = 40\n",
    "plt.plot(pdfs_discretized1[whi])\n",
    "riemann_sum_arrays(grid_pdfs1, pdfs_discretized1[whi], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(tempi[0] - qdfs_discretized1[0]).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_oplus1 = wasserstein_frechet_mean(qdfs_discretized1, grid_pdfs1, grid_qfs1)\n",
    "F_oplus1 = cdf_from_density(grid_pdfs1, f_oplus1, axis=0)\n",
    "f_oplus2 = wasserstein_frechet_mean(qdfs_discretized2, grid_pdfs2, grid_qfs2)\n",
    "F_oplus2 = cdf_from_density(grid_pdfs2, f_oplus2, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nat_center = trunc_norm_pdf(grid_pdfs1, 0, 1, -3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare cross sectional and frechet means to true center\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(grid_pdfs1, f_oplus1, label=\"FrÃ©chet mean\")\n",
    "ax.plot(grid_pdfs1, mean_function1, label=\"Cross sectional mean \")\n",
    "ax.plot(grid_pdfs2,nat_center, label=\"True center\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look how plots of qdfs ranging from 0 to 1 and qdfs almost ranging from 0 to 1 look like\n",
    "wiggle = 0.05\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(grid_pdfs1, f_oplus1, label=\"FrÃ©chet mean 1\")\n",
    "ax.plot(grid_pdfs2, f_oplus2 + wiggle, label=\"FrÃ©chet mean 2\")\n",
    "ax.plot(grid_pdfs1, mean_function1, label=\"Cross sectional mean 1\")\n",
    "ax.plot(grid_pdfs2, mean_function2 + wiggle, label=\"Cross sectional mean 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(grid_pdfs1, f_oplus1, label=\"FrÃ©chet mean pdf\")\n",
    "ax.plot(grid_pdfs1, F_oplus1, label=\"FrÃ©chet mean cdf\")\n",
    "ax.plot(grid_pdfs1, mean_function1, label=\"Cross sectional mean\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
